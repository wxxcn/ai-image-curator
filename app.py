import streamlit as st
import os
from dotenv import load_dotenv
from src.llm_client import LLMClient
from src.image_gen import ImageGenerator
from src.prompt_engine import PromptEngine

load_dotenv()

st.set_page_config(page_title="AI Image Curator (Qwen-Image)", page_icon="ðŸŽ¨", layout="wide")

# --- Initialize Session State ---
if "messages" not in st.session_state:
    st.session_state.messages = []
if "last_final_prompt" not in st.session_state:
    st.session_state.last_final_prompt = ""

# --- Sidebar ---
with st.sidebar:
    st.title("Settings âš™ï¸")
    st.markdown("### Alibaba DashScope (Qwen Family)")
    api_key = st.text_input("DashScope API Key", type="password", value=os.getenv("DASHSCOPE_API_KEY", ""))
    st.caption("Using Qwen-Max for Logic and Qwen-Image-Plus for Art.")
    
    platform = st.selectbox(
        "Target Social Platform ðŸ“±",
        options=list(PromptEngine.PLATFORM_TEMPLATES.keys())
    )
    st.info(f"**Current Style Guide:**\n{PromptEngine.PLATFORM_TEMPLATES[platform]}")
    
    if st.button("Clear Chat History"):
        st.session_state.messages = []
        st.session_state.last_final_prompt = ""
        st.rerun()

# --- Main UI ---
st.title("ðŸŽ¨ AI Image Curator (Qwen-Image)")
st.caption("Powered by Alibaba Qwen-Max & Qwen-Image-Plus. Advanced text rendering and aesthetic quality.")

# Initialize Clients
if api_key:
    llm_client = LLMClient(api_key=api_key)
    image_gen = ImageGenerator(api_key=api_key)
else:
    st.warning("Please enter your DashScope API Key in the sidebar.")
    st.stop()

# Display chat messages
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        if "content" in message:
            st.markdown(message["content"])
        if "image_url" in message:
            st.image(message["image_url"], caption="Generated by Qwen-Image-Plus")
        if "iteration_details" in message:
            with st.expander("View Prompt Iteration Details"):
                st.json(message["iteration_details"])

# Platform to Size Mapping (Qwen-Image specific sizes)
# Supported: 1024*1024, 1280*720, 720*1280 (Standard) OR 1328*1328, 928*1664 etc (Plus)
# To be safe for Qwen-Image-Plus, we use the high-res specific sizes found in logs:
PLATFORM_SIZES = {
    "Default": "1328*1328",          # 1:1 Square
    "Xiaohongshu (å°çº¢ä¹¦)": "928*1664", # 9:16 Vertical
    "Douyin (æŠ–éŸ³)": "928*1664",      # 9:16 Vertical
    "E-commerce (ç”µå•†)": "1328*1328"   # 1:1 Square
}

# Chat Input
if prompt := st.chat_input("What would you like to create? (e.g., 'ä¸€åªå–å’–å•¡çš„å¯çˆ±çŒ«å’ª')"):
    # Check if it's a new request or feedback
    is_feedback = len(st.session_state.messages) > 0 and st.session_state.last_final_prompt != ""
    
    target_size = PLATFORM_SIZES.get(platform, "1024*1024")
    
    with st.chat_message("user"):
        st.markdown(prompt)
    st.session_state.messages.append({"role": "user", "content": prompt})

    with st.chat_message("assistant"):
        with st.status("Thinking & Optimizing Prompt...", expanded=True) as status:
            if not is_feedback:
                # Feature 2: Self-iteration
                st.write("Analyzing intent and applying platform styles...")
                iteration_result = llm_client.optimize_prompt(prompt, platform)
                final_prompt = iteration_result["final_prompt"]
                st.session_state.last_final_prompt = final_prompt
                
                st.write("Critique & Refinement complete.")
                status.update(label="Prompt Optimized!", state="complete", expanded=False)
                
                st.markdown(f"**Final Optimized Prompt (Chinese):**\n`{final_prompt}`")
                st.caption(f"Target Size: `{target_size}`")
                
                # Feature 1: Image Generation
                st.write(f"Generating image with Qwen-Image ({target_size})...")
                image_url = image_gen.generate_image(final_prompt, size=target_size)
                
                if image_url:
                    st.image(image_url)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": f"Here is your image for **{platform}**!",
                        "image_url": image_url,
                        "iteration_details": iteration_result
                    })
                else:
                    st.error("Failed to generate image.")
            else:
                # Feature 1: Based on feedback
                st.write("Adjusting previous prompt based on feedback...")
                new_prompt = llm_client.adjust_prompt_with_feedback(prompt, st.session_state.last_final_prompt)
                st.session_state.last_final_prompt = new_prompt
                
                st.write(f"Generating adjusted image with Wanxiang ({target_size})...")
                image_url = image_gen.generate_image(new_prompt, size=target_size)
                
                if image_url:
                    st.image(image_url)
                    st.session_state.messages.append({
                        "role": "assistant",
                        "content": "I've adjusted the image based on your feedback.",
                        "image_url": image_url,
                        "new_prompt": new_prompt
                    })
                else:
                    st.error("Failed to generate image.")